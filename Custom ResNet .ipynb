{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0c185f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Anh-Vu Nguyen\n",
    " \n",
    "This files defines functions to build custom resnet models.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPool2D, GlobalAvgPool2D\n",
    "from tensorflow.keras.layers import Add, ReLU, Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "###### THIS IS OUR CUSTOM RESNET MODEL GENERATOR #####################\n",
    "# Inputs:\n",
    "# - res_model: list of resnet blocks parmater (eg: [1,3,1],[64,64,256],3] first resnet block of resnet50)  \n",
    "# containing list of kernel sizes ([1,3,1]), filter sizes ([64,64,256]) ,\n",
    "# and multiplicity of resnet blocks (3)\n",
    "# - custom_input: input shape of model \n",
    "# - n_classes: number of classes\n",
    "# - model_name: model name\n",
    "# - debug: prints layers shape if true\n",
    "#\n",
    "#  Defaults parameters correspond to resnet50\n",
    "#\n",
    "#\n",
    "# Output : tensorflow model if the described resnet model\n",
    "######################################################################\n",
    "\n",
    "\n",
    "\n",
    "def custom_resnet(res_model=[],custom_input=(224,224,3),n_classes=1000,model_name='custom_resnet',debug=False):\n",
    "\n",
    "    # default model is resnet50\n",
    "    if len(res_model)==0:\n",
    "        model_name='custom_resnet50'\n",
    "        \n",
    "        #resnet50 parameters\n",
    "        #https://pytorch.org/assets/images/resnet.png\n",
    "        res_model=[[1,3,1],[64,64,256],3],[[1,3,1],[128,128,512],4],[[1,3,1],[256,256,1024],6],[[1,3,1],[512,512,2048],3]\n",
    "\n",
    "    #layers with 2dconv, batch norm, and relu activation\n",
    "    def conv_and_activation_block(x, filters, kernel_size, strides=1,name=''):\n",
    "        x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding = 'same',name=name+'_conv')(x)\n",
    "        x = BatchNormalization(name=name+'_bn')(x)\n",
    "        x = ReLU(name=name+'_relu')(x)\n",
    "        return x\n",
    "    \n",
    "     #block with the 2Dconv instead of the skip connection\n",
    "    def first_resnet_block(input_x, filters,kernels, big_stride,name): \n",
    "        \n",
    "        #sequence with multiple conv\n",
    "        \n",
    "        #first conv has can have a stride 2\n",
    "        x = conv_and_activation_block(input_x, filters=filters[0], kernel_size=kernels[0], strides=big_stride,name=name+'_1')  \n",
    "        \n",
    "        #other conv layers have stride 1\n",
    "        for i in range(len(filters[1:-1])): \n",
    "            x = conv_and_activation_block(x, filters=filters[1+i], kernel_size=kernels[i+1], strides=1,name=name+'_'+str(i+2)) \n",
    "            \n",
    "        #last conv layers not followed by activation\n",
    "        x = Conv2D(filters=filters[-1], kernel_size=kernels[-1], strides=1,padding = 'same',name=name+'_'+str(len(filters))+'_conv')(x)\n",
    "        if debug:\n",
    "            print('first block: ',x.shape)\n",
    "        x = BatchNormalization(name=name+'_'+str(len(filters))+'_bn')(x) \n",
    "\n",
    "        #sequence with only one conv  \n",
    "        shortcut = Conv2D(filters=filters[-1], kernel_size=kernels[-1], strides=big_stride,padding = 'same',name=name+'_0_conv')(input_x)     \n",
    "        shortcut = BatchNormalization(name=name+'_0_bn')(shortcut) \n",
    "        \n",
    "        #add the two sequences\n",
    "        x = Add(name=name+'_add')([shortcut,x])    #skip connection     \n",
    "        x = ReLU(name=name+'_relu')(x)          \n",
    "        return x\n",
    "    \n",
    "    #block with the skip connection\n",
    "    def block_with_skip(input_x, filters,kernels,name):\n",
    "        \n",
    "        #first conv has can have a stride 2\n",
    "        x = conv_and_activation_block(input_x, filters=filters[0], kernel_size=kernels[0], strides=1,name=name+'_1')\n",
    "        #other conv layers have stride 1\n",
    "        for i in range(len(filters[1:-1])): \n",
    "            x = conv_and_activation_block(x, filters=filters[1+i], kernel_size=kernels[i+1], strides=1,name=name+'_'+str(i+2))     \n",
    "            print('2   ',x.shape)\n",
    "        \n",
    "         #last conv layers not followed by activation\n",
    "        x = Conv2D(filters=filters[-1], kernel_size=kernels[-1], strides=1,padding = 'same',name=name+'_'+str(len(filters))+'_conv')(x)     \n",
    "        x = BatchNormalization(name=name+'_'+str(len(filters))+'_bn')(x)\n",
    "        if debug:\n",
    "            print('INPUT SHAPE  ',input_x.shape)\n",
    "            print('conv shape   ',x.shape)\n",
    "        \n",
    "        #skip node\n",
    "        x = Add(name=name+'_add')([input_x,x])    \n",
    "        x = ReLU(name=name+'_relu')(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "    #resnet block\n",
    "    def resnet_block(x,params,big_stride,name): #params=[[1,3,1],[64,64,256],3] FOR EXAMPLE\n",
    "        multiplicity=params[2]-1\n",
    "        filters=params[1]\n",
    "        kernels=params[0]\n",
    "\n",
    "        x = first_resnet_block(x, filters,kernels, big_stride=big_stride,name=name+'_block1')\n",
    "        for i in range(multiplicity):\n",
    "            x = block_with_skip(x,filters,kernels,name=name+'_block'+str(i+2))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Building the custom model all paddings to same!\n",
    "    input = Input(custom_input)\n",
    "\n",
    "    x = conv_and_activation_block(input, filters=64, kernel_size=7, strides=2,name='conv1')\n",
    "    if debug:\n",
    "        print('after first layer   ',x.shape)\n",
    "    x = MaxPool2D(pool_size = 3, strides =2, padding = 'same',name='pool1')(x)\n",
    "    if debug:\n",
    "        print('after maxpool  ',x.shape)\n",
    "    first_res_block=True\n",
    "    for i,res_size in enumerate(res_model):\n",
    "        # The first restnet block have of strides set to 1 because of the previous maxpool!\n",
    "        if first_res_block:\n",
    "            first_res_block=False\n",
    "            x=resnet_block(x,res_size,big_stride=1,name=\"conv\"+str(i+2))#kernels, filters, multiplicity\n",
    "        else:\n",
    "            x=resnet_block(x,res_size,big_stride=2,name=\"conv\"+str(i+2))\n",
    "\n",
    "    x = GlobalAvgPool2D(name='pool_out')(x)\n",
    "\n",
    "    output = Dense(n_classes, activation ='softmax',name='output_layer')(x)\n",
    "\n",
    "    custom_model = Model(inputs=input, outputs=output)\n",
    "    custom_model._name=model_name\n",
    "    return custom_model\n",
    "\n",
    "# prints the resnet layer descriptions\n",
    "def custom_resnet_summary(res_model=[]):\n",
    "    model=custom_resnet(res_model)\n",
    "    model.summary()\n",
    "    \n",
    "# builds resnet18\n",
    "# https://pytorch.org/assets/images/resnet.png for more information\n",
    "def custom_resnet18(input_shape=(224,224,3),n_classes=1000,name='custom_resnet18',debug=False):\n",
    "    return  custom_resnet([[[3,3],[64,64],2],[[3,3],[128,128],2],[[3,3],[256,256],2],[[3,3],[512,512],2]],input_shape,n_classes,name,debug)\n",
    "\n",
    "# builds resnet34\n",
    "# https://pytorch.org/assets/images/resnet.png for more information\n",
    "def custom_resnet34(input_shape=(224,224,3),n_classes=1000,name='custom_resnet34',debug=False):\n",
    "    return  custom_resnet([[[3,3],[64,64],3],[[3,3],[128,128],4],[[3,3],[256,256],6],[[3,3],[512,512],3]],input_shape,n_classes,name,debug)\n",
    "\n",
    "def custom_resnet50(input_shape=(224,224,3),n_classes=1000,name='custom_resnet50',debug=False):\n",
    "    return  custom_resnet([],input_shape,n_classes,name,False)\n",
    "\n",
    "# builds resnet101\n",
    "# https://pytorch.org/assets/images/resnet.png for more information\n",
    "def custom_resnet101(input_shape=(224,224,3),n_classes=1000,name='custom_resnet101',debug=False):\n",
    "    return  custom_resnet([[1,3,1],[64,64,256],3],[[1,3,1],[128,128,512],4],[[1,3,1],[256,256,1024],23],[[1,3,1],[512,512,2048],3],input_shape,n_classes,name,debug)\n",
    "\n",
    "# builds resnet152\n",
    "# https://pytorch.org/assets/images/resnet.png for more information\n",
    "def custom_resnet152(input_shape=(224,224,3),n_classes=1000,name='custom_resnet152',debug=False):\n",
    "    return  custom_resnet([[1,3,1],[64,64,256],3],[[1,3,1],[128,128,512],4],[[1,3,1],[256,256,1024],36],[[1,3,1],[512,512,2048],3],input_shape,n_classes,name,debug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7bae7e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"64x64resnet18_200classes\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 32, 32, 64)   9472        input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 32, 32, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (ReLU)               (None, 32, 32, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 16, 16, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   36928       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (ReLU)      (None, 16, 16, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 16, 16, 64)   36928       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 16, 16, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_relu (ReLU)        (None, 16, 16, 64)   0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (ReLU)      (None, 16, 16, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 16, 16, 64)   0           conv2_block1_relu[0][0]          \n",
      "                                                                 conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_relu (ReLU)        (None, 16, 16, 64)   0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    73856       conv2_block2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (ReLU)      (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 8, 8, 128)    73856       conv2_block2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 8, 8, 128)    0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_relu (ReLU)        (None, 8, 8, 128)    0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (ReLU)      (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 8, 8, 128)    0           conv3_block1_relu[0][0]          \n",
      "                                                                 conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_relu (ReLU)        (None, 8, 8, 128)    0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 256)    295168      conv3_block2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 4, 4, 256)    295168      conv3_block2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 4, 4, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_relu (ReLU)        (None, 4, 4, 256)    0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 4, 4, 256)    0           conv4_block1_relu[0][0]          \n",
      "                                                                 conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_relu (ReLU)        (None, 4, 4, 256)    0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    1180160     conv4_block2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (ReLU)      (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 2, 2, 512)    1180160     conv4_block2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 2, 2, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_relu (ReLU)        (None, 2, 2, 512)    0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (ReLU)      (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 2, 2, 512)    0           conv5_block1_relu[0][0]          \n",
      "                                                                 conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_relu (ReLU)        (None, 2, 2, 512)    0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool_out (GlobalAveragePooling2 (None, 512)          0           conv5_block2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 200)          102600      pool_out[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,706,952\n",
      "Trainable params: 12,697,224\n",
      "Non-trainable params: 9,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=custom_resnet18(input_shape=(64,64,3),n_classes=200,name='64x64resnet18_200classes')\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
