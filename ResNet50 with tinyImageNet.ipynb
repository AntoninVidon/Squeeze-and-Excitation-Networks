{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb541af4",
   "metadata": {},
   "source": [
    "The dataset Tiny ImageNet has to be in the 'data/' folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f2234",
   "metadata": {},
   "source": [
    "Instruction to download and extract the data:\n",
    "\n",
    "wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "\n",
    "unzip tiny-imagenet-200.zip\n",
    "\n",
    "rm tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9913ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac925a",
   "metadata": {},
   "source": [
    "# 0. Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c35132",
   "metadata": {},
   "source": [
    "### TinyImageNet does not have labels for the testing data. We will use the 10k validation images for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513cdce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497 pictures in folder n03617480\n",
      "499 pictures in folder n09332890\n",
      "499 pictures in folder n01917289\n",
      "497 pictures in folder n04398044\n",
      "496 pictures in folder n03977966\n",
      "491 pictures in folder n04486054\n",
      "485 pictures in folder n02481823\n",
      "499 pictures in folder n01910747\n",
      "500 pictures in folder n01443537\n",
      "495 pictures in folder n02823428\n",
      "497 pictures in folder n04254777\n",
      "487 pictures in folder n03837869\n",
      "500 pictures in folder n07695742\n",
      "493 pictures in folder n03983396\n",
      "500 pictures in folder n04597913\n",
      "495 pictures in folder n02395406\n",
      "500 pictures in folder n02132136\n",
      "492 pictures in folder n04259630\n",
      "500 pictures in folder n02279972\n",
      "493 pictures in folder n04371430\n",
      "500 pictures in folder n03980874\n",
      "454 pictures in folder n03763968\n",
      "499 pictures in folder n07768694\n",
      "497 pictures in folder n02948072\n",
      "497 pictures in folder n02231487\n",
      "497 pictures in folder n02206856\n",
      "494 pictures in folder n09428293\n",
      "498 pictures in folder n03100240\n",
      "473 pictures in folder n04532670\n",
      "495 pictures in folder n01944390\n",
      "495 pictures in folder n02099712\n",
      "491 pictures in folder n03733131\n",
      "500 pictures in folder n07579787\n",
      "500 pictures in folder n01983481\n",
      "499 pictures in folder n02415577\n",
      "500 pictures in folder n03662601\n",
      "496 pictures in folder n01698640\n",
      "497 pictures in folder n01774384\n",
      "465 pictures in folder n04356056\n",
      "466 pictures in folder n03388043\n",
      "481 pictures in folder n03599486\n",
      "485 pictures in folder n04399382\n",
      "495 pictures in folder n02233338\n",
      "480 pictures in folder n03404251\n",
      "498 pictures in folder n04251144\n",
      "491 pictures in folder n02808440\n",
      "485 pictures in folder n02814860\n",
      "498 pictures in folder n02058221\n",
      "491 pictures in folder n02906734\n",
      "471 pictures in folder n04376876\n",
      "498 pictures in folder n03796401\n",
      "499 pictures in folder n03089624\n",
      "473 pictures in folder n03891332\n",
      "500 pictures in folder n09256479\n",
      "495 pictures in folder n04070727\n",
      "490 pictures in folder n03970156\n",
      "494 pictures in folder n02815834\n",
      "498 pictures in folder n04456115\n",
      "480 pictures in folder n03126707\n",
      "483 pictures in folder n03160309\n",
      "500 pictures in folder n02730930\n",
      "480 pictures in folder n04023962\n",
      "491 pictures in folder n02113799\n",
      "496 pictures in folder n03706229\n",
      "477 pictures in folder n04507155\n",
      "500 pictures in folder n07734744\n",
      "500 pictures in folder n02226429\n",
      "500 pictures in folder n01984695\n",
      "497 pictures in folder n02125311\n",
      "489 pictures in folder n03584254\n",
      "500 pictures in folder n01950731\n",
      "499 pictures in folder n02268443\n",
      "496 pictures in folder n03444034\n",
      "496 pictures in folder n02364673\n",
      "473 pictures in folder n04366367\n",
      "500 pictures in folder n07875152\n",
      "498 pictures in folder n02074367\n",
      "497 pictures in folder n03014705\n",
      "494 pictures in folder n03854065\n",
      "497 pictures in folder n02699494\n",
      "494 pictures in folder n09193705\n",
      "484 pictures in folder n04275548\n",
      "494 pictures in folder n03042490\n",
      "485 pictures in folder n04008634\n",
      "496 pictures in folder n12267677\n",
      "479 pictures in folder n03255030\n",
      "500 pictures in folder n07583066\n",
      "467 pictures in folder n03930313\n",
      "492 pictures in folder n04560804\n",
      "494 pictures in folder n02099601\n",
      "479 pictures in folder n04074963\n",
      "499 pictures in folder n04118538\n",
      "500 pictures in folder n07614500\n",
      "494 pictures in folder n02988304\n",
      "500 pictures in folder n01629819\n",
      "498 pictures in folder n01855672\n",
      "495 pictures in folder n02486410\n",
      "498 pictures in folder n01644900\n",
      "473 pictures in folder n04311004\n",
      "474 pictures in folder n02837789\n",
      "500 pictures in folder n07747607\n",
      "486 pictures in folder n02843684\n",
      "488 pictures in folder n03937543\n",
      "494 pictures in folder n02410509\n",
      "481 pictures in folder n04067472\n",
      "500 pictures in folder n01641577\n",
      "500 pictures in folder n07873807\n",
      "496 pictures in folder n03355925\n",
      "492 pictures in folder n02123394\n",
      "497 pictures in folder n01945685\n",
      "497 pictures in folder n02802426\n",
      "453 pictures in folder n02791270\n",
      "498 pictures in folder n02769748\n",
      "500 pictures in folder n02963159\n",
      "499 pictures in folder n01742172\n",
      "474 pictures in folder n04179913\n",
      "497 pictures in folder n02927161\n",
      "493 pictures in folder n02977058\n",
      "485 pictures in folder n03976657\n",
      "498 pictures in folder n04146614\n",
      "500 pictures in folder n04532106\n",
      "493 pictures in folder n02403003\n",
      "492 pictures in folder n03670208\n",
      "492 pictures in folder n01768244\n",
      "473 pictures in folder n04562935\n",
      "499 pictures in folder n02509815\n",
      "494 pictures in folder n04487081\n",
      "499 pictures in folder n03026506\n",
      "499 pictures in folder n02002724\n",
      "499 pictures in folder n03393912\n",
      "495 pictures in folder n03770439\n",
      "474 pictures in folder n03992509\n",
      "468 pictures in folder n03804744\n",
      "491 pictures in folder n03814639\n",
      "497 pictures in folder n01770393\n",
      "500 pictures in folder n02056570\n",
      "497 pictures in folder n02094433\n",
      "498 pictures in folder n07920052\n",
      "497 pictures in folder n02085620\n",
      "499 pictures in folder n07720875\n",
      "495 pictures in folder n03400231\n",
      "492 pictures in folder n02892201\n",
      "496 pictures in folder n02504458\n",
      "480 pictures in folder n03424325\n",
      "479 pictures in folder n02950826\n",
      "497 pictures in folder n04149813\n",
      "452 pictures in folder n03544143\n",
      "496 pictures in folder n02423022\n",
      "482 pictures in folder n04328186\n",
      "474 pictures in folder n03250847\n",
      "491 pictures in folder n02814533\n",
      "491 pictures in folder n02480495\n",
      "477 pictures in folder n03902125\n",
      "471 pictures in folder n02841315\n",
      "481 pictures in folder n02793495\n",
      "497 pictures in folder n02190166\n",
      "466 pictures in folder n03085013\n",
      "500 pictures in folder n07871810\n",
      "460 pictures in folder n02883205\n",
      "488 pictures in folder n04417672\n",
      "484 pictures in folder n03637318\n",
      "500 pictures in folder n01784675\n",
      "465 pictures in folder n02788148\n",
      "473 pictures in folder n04501370\n",
      "488 pictures in folder n02909870\n",
      "492 pictures in folder n02106662\n",
      "499 pictures in folder n07749582\n",
      "499 pictures in folder n02236044\n",
      "500 pictures in folder n02281406\n",
      "463 pictures in folder n03838899\n",
      "485 pictures in folder n04099969\n",
      "495 pictures in folder n04285008\n",
      "488 pictures in folder n02669723\n",
      "492 pictures in folder n02666196\n",
      "493 pictures in folder n07753592\n",
      "498 pictures in folder n07615774\n",
      "480 pictures in folder n04465501\n",
      "484 pictures in folder n02795169\n",
      "492 pictures in folder n02917067\n",
      "495 pictures in folder n04133789\n",
      "495 pictures in folder n01774750\n",
      "499 pictures in folder n01882714\n",
      "495 pictures in folder n03649909\n",
      "500 pictures in folder n02321529\n",
      "497 pictures in folder n06596364\n",
      "492 pictures in folder n02123045\n",
      "492 pictures in folder n02124075\n",
      "493 pictures in folder n02129165\n",
      "500 pictures in folder n02165456\n",
      "496 pictures in folder n09246464\n",
      "500 pictures in folder n07711569\n",
      "490 pictures in folder n04265275\n",
      "497 pictures in folder n07715103\n",
      "493 pictures in folder n03179701\n",
      "480 pictures in folder n03447447\n",
      "494 pictures in folder n04596742\n",
      "500 pictures in folder n03201208\n",
      "472 pictures in folder n02999410\n",
      "498 pictures in folder n02437312\n",
      "494 pictures in folder n04540053\n"
     ]
    }
   ],
   "source": [
    "#Generate dataset\n",
    "\n",
    "###### TRAINING DATA #######\n",
    "#Load Training images and labels\n",
    "train_directory = \"./data/tiny-imagenet-200/train\" \n",
    "image_list=[]\n",
    "label_list=[]\n",
    "\n",
    "label_dic={} #convert label str to int from 0 \n",
    "\n",
    "\n",
    "\n",
    "for l,sub_dir in enumerate(os.listdir(train_directory)):\n",
    "    if not sub_dir in label_dic:\n",
    "        label_dic[sub_dir]=l\n",
    "    sub_dir_name=os.path.join(train_directory,sub_dir,'images')\n",
    "    n=0\n",
    "    for file in os.listdir(sub_dir_name):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".JPEG\")  or filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img=np.array(Image.open(os.path.join(sub_dir_name,file)))\n",
    "            if(img.shape == (64, 64, 3)): #removing images without 3 channels\n",
    "                image_list.append(img)\n",
    "                label_list.append(int(label_dic[sub_dir]))\n",
    "                n+=1\n",
    "    print(n,'pictures in folder',sub_dir,sep=' ' )\n",
    "            \n",
    "X_tot=np.array(image_list)\n",
    "y_tot=np.array(label_list)\n",
    "\n",
    "###### TEST DATA #######\n",
    "\n",
    "#getting the labels from the txt file\n",
    "df = pd.read_table('./data/tiny-imagenet-200/val/val_annotations.txt', header=None)\n",
    "test_labels={} \n",
    "for index, row in df.iterrows():\n",
    "    test_labels[str(row[0])]= row[1]\n",
    "\n",
    "\n",
    "test_directory = \"./data/tiny-imagenet-200/val/images\" \n",
    "\n",
    "test_image_list=[]\n",
    "test_label_list=[]\n",
    "\n",
    "for file in os.listdir(test_directory):\n",
    "    filename = os.fsdecode(file)\n",
    "  \n",
    "    if filename.endswith(\".JPEG\")  or filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        img=np.array(Image.open(os.path.join(test_directory,file)))\n",
    "        if(img.shape == (64, 64, 3)): #removing images without 3 channels\n",
    "            test_image_list.append(img)\n",
    "            test_label_list.append(label_dic[test_labels[filename]])\n",
    "            \n",
    "X_test=np.array(test_image_list)\n",
    "y_test=tf.keras.utils.to_categorical(np.array(test_label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df1e044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data:\n",
      "(9832, 64, 64, 3)\n",
      "(9832, 200)\n",
      "train data:\n",
      "(93179, 64, 64, 3)\n",
      "(93179, 200)\n",
      "val data:\n",
      "(5000, 64, 64, 3)\n",
      "(5000, 200)\n"
     ]
    }
   ],
   "source": [
    "shuffler=np.random.RandomState(seed=10).permutation(len(X_tot))\n",
    "X_tot = X_tot[shuffler]\n",
    "y_tot = y_tot[shuffler]\n",
    "y_tot=tf.keras.utils.to_categorical(y_tot)\n",
    "\n",
    "X_train = X_tot[5000:]\n",
    "y_train =  y_tot[5000:]\n",
    "X_val = X_tot[:5000]\n",
    "y_val =  y_tot[:5000]\n",
    "\n",
    "\n",
    "print('test data:')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print('train data:')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('val data:')\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f0b69",
   "metadata": {},
   "source": [
    "#### Saving the variables allows faster loading in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04ce48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save for future use without having to reload from the images folders\n",
    "np.save('data/X_test.npy', X_test)\n",
    "np.save('data/y_test.npy', y_test)\n",
    "np.save('data/X_train.npy', X_train)\n",
    "np.save('data/y_train.npy', y_train)\n",
    "np.save('data/X_val.npy', X_val)\n",
    "np.save('data/y_val.npy', y_val) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954ab98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script running in C:\\Users\\nguye\\Documents\\GitHub\\e4040-2021fall-project-fren-an3078-wab2138-av3023\n"
     ]
    }
   ],
   "source": [
    "print('script running in '+os.path.abspath(\".\"))\n",
    "X_test = np.load('./data/X_test.npy')\n",
    "y_test = np.load('./data/y_test.npy')\n",
    "X_train = np.load('./data/X_train.npy')\n",
    "y_train = np.load('./data/y_train.npy')\n",
    "X_val = np.load('./data/X_val.npy')\n",
    "y_val = np.load('./data/y_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215a9fd",
   "metadata": {},
   "source": [
    "## 3.1 Resnet50 without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2998d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 32, 32, 64)   9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 32, 32, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (ReLU)               (None, 32, 32, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 16, 16, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   4160        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (ReLU)      (None, 16, 16, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (ReLU)      (None, 16, 16, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 16, 16, 256)  16640       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 16, 16, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_relu (ReLU)        (None, 16, 16, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (ReLU)      (None, 16, 16, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (ReLU)      (None, 16, 16, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 16, 16, 256)  0           conv2_block1_relu[0][0]          \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_relu (ReLU)        (None, 16, 16, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (ReLU)      (None, 16, 16, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (ReLU)      (None, 16, 16, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 16, 16, 256)  0           conv2_block2_relu[0][0]          \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_relu (ReLU)        (None, 16, 16, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32896       conv2_block3_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (ReLU)      (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (ReLU)      (None, 8, 8, 128)    0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 8, 8, 512)    131584      conv2_block3_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 8, 8, 512)    0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_relu (ReLU)        (None, 8, 8, 512)    0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (ReLU)      (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (ReLU)      (None, 8, 8, 128)    0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 8, 8, 512)    0           conv3_block1_relu[0][0]          \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_relu (ReLU)        (None, 8, 8, 512)    0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (ReLU)      (None, 8, 8, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (ReLU)      (None, 8, 8, 128)    0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 8, 8, 512)    0           conv3_block2_relu[0][0]          \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_relu (ReLU)        (None, 8, 8, 512)    0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block3_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (ReLU)      (None, 8, 8, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (ReLU)      (None, 8, 8, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 8, 8, 512)    0           conv3_block3_relu[0][0]          \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_relu (ReLU)        (None, 8, 8, 512)    0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 256)    131328      conv3_block4_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 4, 4, 1024)   525312      conv3_block4_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_relu (ReLU)        (None, 4, 4, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_relu[0][0]          \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_relu (ReLU)        (None, 4, 4, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 4, 4, 1024)   0           conv4_block2_relu[0][0]          \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_relu (ReLU)        (None, 4, 4, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block3_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 4, 4, 1024)   0           conv4_block3_relu[0][0]          \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_relu (ReLU)        (None, 4, 4, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block4_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 4, 4, 1024)   0           conv4_block4_relu[0][0]          \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_relu (ReLU)        (None, 4, 4, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block5_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (ReLU)      (None, 4, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 4, 4, 1024)   0           conv4_block5_relu[0][0]          \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_relu (ReLU)        (None, 4, 4, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    524800      conv4_block6_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (ReLU)      (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (ReLU)      (None, 2, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 2, 2, 2048)   2099200     conv4_block6_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_relu (ReLU)        (None, 2, 2, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (ReLU)      (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (ReLU)      (None, 2, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_relu[0][0]          \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_relu (ReLU)        (None, 2, 2, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (ReLU)      (None, 2, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (ReLU)      (None, 2, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 2, 2, 2048)   0           conv5_block2_relu[0][0]          \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_relu (ReLU)        (None, 2, 2, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool_out (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 200)          409800      pool_out[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,997,512\n",
      "Trainable params: 23,944,392\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from utils.custom_resnet import custom_resnet50\n",
    "from utils.train_TinyImageNet_SE_ResNet import tinyImageNet_resnet_train\n",
    "# tinyImageNet_resnet_train(model,path,X_train,y_train,X_val,y_val,data_aug=False,learning_rate=0.6,steps=14,epochs=45,batch_size=128,es_patience=8)\n",
    "resnet_50=custom_resnet50(input_shape=(64,64,3),n_classes=200)\n",
    "resnet_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b171ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "steps before lr change:  20\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 113s 132ms/step - loss: 7.0651 - acc: 0.0075 - val_loss: 5.1193 - val_acc: 0.0156\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.01560, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 2/60\n",
      "steps before lr change:  19\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 77s 106ms/step - loss: 5.0861 - acc: 0.0165 - val_loss: 5.0441 - val_acc: 0.0236\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.01560 to 0.02360, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 3/60\n",
      "steps before lr change:  18\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 5.0050 - acc: 0.0234 - val_loss: 4.8807 - val_acc: 0.0356\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.02360 to 0.03560, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 4/60\n",
      "steps before lr change:  17\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 77s 107ms/step - loss: 4.8908 - acc: 0.0309 - val_loss: 4.8515 - val_acc: 0.0346\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.03560\n",
      "Epoch 5/60\n",
      "steps before lr change:  16\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 4.8123 - acc: 0.0373 - val_loss: 4.7289 - val_acc: 0.0480\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.03560 to 0.04800, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 6/60\n",
      "steps before lr change:  15\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 4.7328 - acc: 0.0445 - val_loss: 6.0987 - val_acc: 0.0290\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.04800\n",
      "Epoch 7/60\n",
      "steps before lr change:  14\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 4.7018 - acc: 0.0481 - val_loss: 4.6244 - val_acc: 0.0610\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.04800 to 0.06100, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 8/60\n",
      "steps before lr change:  13\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 4.5761 - acc: 0.0648 - val_loss: 4.5462 - val_acc: 0.0632\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.06100 to 0.06320, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 9/60\n",
      "steps before lr change:  12\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 108ms/step - loss: 4.4983 - acc: 0.0679 - val_loss: 4.5107 - val_acc: 0.0610\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.06320\n",
      "Epoch 10/60\n",
      "steps before lr change:  11\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 4.4310 - acc: 0.0772 - val_loss: 4.5237 - val_acc: 0.0688\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.06320 to 0.06880, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 11/60\n",
      "steps before lr change:  10\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 4.3662 - acc: 0.0835 - val_loss: 4.3905 - val_acc: 0.0846\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.06880 to 0.08460, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 12/60\n",
      "steps before lr change:  9\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 4.2977 - acc: 0.0938 - val_loss: 4.4069 - val_acc: 0.0834\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.08460\n",
      "Epoch 13/60\n",
      "steps before lr change:  8\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 108ms/step - loss: 4.2980 - acc: 0.0932 - val_loss: 4.3977 - val_acc: 0.0892\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.08460 to 0.08920, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 14/60\n",
      "steps before lr change:  7\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 77s 106ms/step - loss: 4.2966 - acc: 0.0961 - val_loss: 4.3383 - val_acc: 0.1012\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.08920 to 0.10120, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 15/60\n",
      "steps before lr change:  6\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 77s 106ms/step - loss: 4.1407 - acc: 0.1151 - val_loss: 4.1883 - val_acc: 0.1142\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.10120 to 0.11420, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 16/60\n",
      "steps before lr change:  5\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 77s 106ms/step - loss: 4.0186 - acc: 0.1315 - val_loss: 4.1258 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.11420 to 0.12360, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 17/60\n",
      "steps before lr change:  4\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 108ms/step - loss: 3.8962 - acc: 0.1481 - val_loss: 4.0608 - val_acc: 0.1346\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.12360 to 0.13460, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 18/60\n",
      "steps before lr change:  3\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 108ms/step - loss: 3.7858 - acc: 0.1647 - val_loss: 4.4206 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.13460\n",
      "Epoch 19/60\n",
      "steps before lr change:  2\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 108ms/step - loss: 3.6971 - acc: 0.1780 - val_loss: 4.1243 - val_acc: 0.1488\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.13460 to 0.14880, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 20/60\n",
      "steps before lr change:  1\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "727/727 [==============================] - 78s 108ms/step - loss: 3.5852 - acc: 0.1901 - val_loss: 4.0293 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.14880\n",
      "Epoch 21/60\n",
      "steps before lr change:  20\n",
      "new learning rate:  0.6000000238418579\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 82s 113ms/step - loss: 3.2297 - acc: 0.2502 - val_loss: 3.9184 - val_acc: 0.1792\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.14880 to 0.17920, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 22/60\n",
      "steps before lr change:  19\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 79s 109ms/step - loss: 2.9749 - acc: 0.2972 - val_loss: 3.9806 - val_acc: 0.1814\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.17920 to 0.18140, saving model to ./models/tinyImageNet\\resnet_50_best.hdf5\n",
      "Epoch 23/60\n",
      "steps before lr change:  18\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 108ms/step - loss: 2.8354 - acc: 0.3202 - val_loss: 4.0781 - val_acc: 0.1734\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.18140\n",
      "Epoch 24/60\n",
      "steps before lr change:  17\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 108ms/step - loss: 2.7242 - acc: 0.3383 - val_loss: 4.2860 - val_acc: 0.1730\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.18140\n",
      "Epoch 25/60\n",
      "steps before lr change:  16\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727/727 [==============================] - 78s 108ms/step - loss: 2.5928 - acc: 0.3583 - val_loss: 4.2913 - val_acc: 0.1690\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.18140\n",
      "Epoch 26/60\n",
      "steps before lr change:  15\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 2.4610 - acc: 0.3831 - val_loss: 4.4593 - val_acc: 0.1690\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.18140\n",
      "Epoch 27/60\n",
      "steps before lr change:  14\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 2.3112 - acc: 0.4114 - val_loss: 4.6008 - val_acc: 0.1642\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.18140\n",
      "Epoch 28/60\n",
      "steps before lr change:  13\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 2.1586 - acc: 0.4438 - val_loss: 4.8643 - val_acc: 0.1610\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.18140\n",
      "Epoch 29/60\n",
      "steps before lr change:  12\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 77s 106ms/step - loss: 1.9910 - acc: 0.4772 - val_loss: 5.1123 - val_acc: 0.1560\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.18140\n",
      "Epoch 30/60\n",
      "steps before lr change:  11\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 77s 106ms/step - loss: 1.8501 - acc: 0.5029 - val_loss: 5.3179 - val_acc: 0.1562\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.18140\n",
      "Epoch 31/60\n",
      "steps before lr change:  10\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 108ms/step - loss: 1.6836 - acc: 0.5419 - val_loss: 5.5800 - val_acc: 0.1538\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.18140\n",
      "Epoch 32/60\n",
      "steps before lr change:  9\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 1.5432 - acc: 0.5753 - val_loss: 5.9449 - val_acc: 0.1510\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.18140\n",
      "Epoch 33/60\n",
      "steps before lr change:  8\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 1.4124 - acc: 0.6039 - val_loss: 6.1762 - val_acc: 0.1436\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.18140\n",
      "Epoch 34/60\n",
      "steps before lr change:  7\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 1.2957 - acc: 0.6321 - val_loss: 6.5400 - val_acc: 0.1468\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.18140\n",
      "Epoch 35/60\n",
      "steps before lr change:  6\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 1.1947 - acc: 0.6574 - val_loss: 6.9251 - val_acc: 0.1440\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.18140\n",
      "Epoch 36/60\n",
      "steps before lr change:  5\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 1.0834 - acc: 0.6874 - val_loss: 7.8083 - val_acc: 0.1434\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.18140\n",
      "Epoch 37/60\n",
      "steps before lr change:  4\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 0.9858 - acc: 0.7157 - val_loss: 7.3065 - val_acc: 0.1428\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.18140\n",
      "Epoch 38/60\n",
      "steps before lr change:  3\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 0.8957 - acc: 0.7381 - val_loss: 7.6029 - val_acc: 0.1358\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.18140\n",
      "Epoch 39/60\n",
      "steps before lr change:  2\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 0.8333 - acc: 0.7557 - val_loss: 8.1760 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.18140\n",
      "Epoch 40/60\n",
      "steps before lr change:  1\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.06000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 0.7555 - acc: 0.7763 - val_loss: 7.9897 - val_acc: 0.1384\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.18140\n",
      "Epoch 41/60\n",
      "steps before lr change:  20\n",
      "new learning rate:  0.06000000238418579\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.006000000238418579.\n",
      "727/727 [==============================] - 78s 107ms/step - loss: 0.5504 - acc: 0.8437 - val_loss: 8.4906 - val_acc: 0.1476\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.18140\n",
      "Epoch 42/60\n",
      "steps before lr change:  19\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.006000000052154064.\n",
      "727/727 [==============================] - 78s 108ms/step - loss: 0.3247 - acc: 0.9181 - val_loss: 8.9116 - val_acc: 0.1410\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.18140\n"
     ]
    }
   ],
   "source": [
    "hist_resnet_50= tinyImageNet_resnet_train(resnet_50,\n",
    "                          './models/tinyImageNet/resnet_50_best.hdf5', #path for weights of best model\n",
    "                          X_train,y_train,\n",
    "                          X_val,\n",
    "                          y_val,\n",
    "                          data_aug=False, #no data aug\n",
    "                          learning_rate=0.6, #starting learning rate\n",
    "                          steps=20, #number of epochs between learning rate modification (* 0.1)\n",
    "                          epochs=60,\n",
    "                          batch_size=128,\n",
    "                          es_patience=20) #early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82be3609",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist_resnet_50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_192/3243397008.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_TinyImageNet_SE_ResNet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist_resnet_50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hist_resnet_50' is not defined"
     ]
    }
   ],
   "source": [
    "from utils.train_TinyImageNet_SE_ResNet import plot_model\n",
    "plot_model(hist_resnet_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3952a237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 - 12s - loss: 4.0294 - acc: 0.1837\n",
      "best saved model, accuracy: 18.37%\n",
      "308/308 - 5s - loss: 4.0294 - acc: 0.1837\n",
      "custom_resnet50\n",
      "model accuracy: 18.37%\n",
      "top 1 accuracy: 0.18368593\n",
      "top 3 accuracy: 0.32607812\n",
      "top 5 accuracy: 0.40052888\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# reload from saved weights:\n",
    "model = custom_resnet50(input_shape=(64,64,3),n_classes=200)\n",
    "model.load_weights('./models/tinyImageNet/resnet_50_best.hdf5')\n",
    "\n",
    "# Evaluate the model\n",
    "model.compile(loss='categorical_crossentropy', metrics = ['acc'])\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"best saved model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "\n",
    "from utils.evaluate_model import score\n",
    "score(model,X_test,y_test,[1,3,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0cb69",
   "metadata": {},
   "source": [
    "## 3.2 Resnet50 with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_TinyImageNet_SE_ResNet import tinyImageNet_resnet_train,plot_model\n",
    "from utils.custom_resnet import custom_resnet50\n",
    "\n",
    "resnet_50_aug=custom_resnet50(input_shape=(64,64,3),n_classes=200)\n",
    "path='./models/tinyImageNet/resnet_50_aug_best.hdf5'\n",
    "history_resnet_50_aug= tinyImageNet_resnet_train(resnet_50_aug,\n",
    "                          path, #path for weights of best model\n",
    "                          X_train,y_train,\n",
    "                          X_val,\n",
    "                          y_val,\n",
    "                          data_aug=True, #no data aug\n",
    "                          learning_rate=0.6, #starting learning rate\n",
    "                          steps=20, #number of epochs between learning rate modification (* 0.1)\n",
    "                          epochs=60,\n",
    "                          batch_size=128,\n",
    "                          es_patience=20) #early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed4fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(history_resnet_50_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from saved weights:\n",
    "model = custom_resnet50(input_shape=(64,64,3),n_classes=200)\n",
    "model.load_weights(path)\n",
    "\n",
    "# Evaluate the model\n",
    "from utils.evaluate_model import score\n",
    "score(model,X_test,y_test,[1,3,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc434d",
   "metadata": {},
   "source": [
    "## 4.1 SE-ResNet50 without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ccd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SE_resnet import SE_resnet50\n",
    "\n",
    "SE_resnet50=SE_resnet50(input_shape=(64,64,3),n_classes=200,name='SE_resnet50')\n",
    "SE_resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d445f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./models/tinyImageNet/SE-resnet_50_best.hdf5'\n",
    "history_SEresnet_50= tinyImageNet_resnet_train(SE_resnet50,\n",
    "                          path, #path for weights of best model\n",
    "                          X_train,y_train,\n",
    "                          X_val,\n",
    "                          y_val,\n",
    "                          data_aug=False, #no data aug\n",
    "                          learning_rate=0.6, #starting learning rate\n",
    "                          steps=20, #number of epochs between learning rate modification (* 0.1)\n",
    "                          epochs=60,\n",
    "                          batch_size=128,\n",
    "                          es_patience=20) #early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(history_SEresnet_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fef5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from saved weights:\n",
    "from utils.SE_resnet import SE_resnet50\n",
    "model = SE_resnet50(input_shape=(64,64,3),n_classes=200,name='SE_resnet50')\n",
    "model.load_weights(path)\n",
    "\n",
    "# Evaluate the model\n",
    "from utils.evaluate_model import score\n",
    "score(model,X_test,y_test,[1,3,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1cda17",
   "metadata": {},
   "source": [
    "## 4.2 SE-ResNet50 with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b655c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SE_resnet import SE_resnet50\n",
    "\n",
    "SE_resnet50_aug=SE_resnet50(input_shape=(64,64,3),n_classes=200,name='SE_resnet50_aug')\n",
    "\n",
    "path='./models/tinyImageNet/SE-resnet_50_aug_best.hdf5'\n",
    "history_SEresnet_50_aug= tinyImageNet_resnet_train(SE_resnet50_aug,\n",
    "                          path, #path for weights of best model\n",
    "                          X_train,y_train,\n",
    "                          X_val,\n",
    "                          y_val,\n",
    "                          data_aug=True, #no data aug\n",
    "                          learning_rate=0.6, #starting learning rate\n",
    "                          steps=20, #number of epochs between learning rate modification (* 0.1)\n",
    "                          epochs=60,\n",
    "                          batch_size=128,\n",
    "                          es_patience=20) #early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(history_SEresnet_50_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from saved weights:\n",
    "from utils.SE_resnet import SE_resnet50\n",
    "model = SE_resnet50(input_shape=(64,64,3),n_classes=200,name='SE_resnet50_aug')\n",
    "model.load_weights(path)\n",
    "\n",
    "# Evaluate the model\n",
    "from utils.evaluate_model import score\n",
    "score(model,X_test,y_test,[1,3,5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
