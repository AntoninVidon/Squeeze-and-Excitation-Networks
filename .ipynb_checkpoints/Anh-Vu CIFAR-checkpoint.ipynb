{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405d9804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.client import device_lib\n",
    "#check if gpu available\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) \n",
    "# gpu memory\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc84cc60",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47dbbeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical  \n",
    "\n",
    "#load cifar-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "#one hot encoding\n",
    "y_test=to_categorical(y_test, num_classes=10)\n",
    "y_train=to_categorical(y_train, num_classes=10)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9724e20",
   "metadata": {},
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e72a6b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data and split data to generate validation data\n",
    "shuffler = np.random.permutation(len(x_train))\n",
    "x_train = x_train[shuffler]\n",
    "y_train = y_train[shuffler]\n",
    " \n",
    "\n",
    "#validation data\n",
    "x_val=x_train[0:2000]\n",
    "y_val=y_train[0:2000]\n",
    "\n",
    "x_train=x_train[2000:]\n",
    "y_train=y_train[2000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c61ffb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "epochs=3\n",
    "base_learning_rate=0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b398b2",
   "metadata": {},
   "source": [
    "### Load ResNet50 without pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a5ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "resnet50 = ResNet50( include_top=False, weights=None)\n",
    "\n",
    "#handles the different input siz\n",
    "preprocess_input =tf.keras.applications.resnet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4ccd8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda) (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, None, None, 2048)  23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "#input\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "# Preprocess for ResNet50 input size\n",
    "x = preprocess_input(inputs)\n",
    "# ResNet50\n",
    "x = resnet50(x)\n",
    "# Add top layer again\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "#10 classes for cifar 10\n",
    "preds=Dense(10,activation='softmax')(x)\n",
    "resnet50_cifar10=Model(inputs=inputs,outputs=preds)\n",
    "resnet50_cifar10.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f169507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/resnet50/conv1_conv/Conv2D (defined at \\AppData\\Local\\Temp/ipykernel_9148/59398938.py:18) ]] [Op:__inference_train_function_13039]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9148/59398938.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m                    \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_size_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                    \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                    validation_data=(x_val, y_val))\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF24\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/resnet50/conv1_conv/Conv2D (defined at \\AppData\\Local\\Temp/ipykernel_9148/59398938.py:18) ]] [Op:__inference_train_function_13039]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "#same with data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "resnet50_cifar10.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss='categorical_crossentropy', metrics = ['acc'])\n",
    "train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        width_shift_range=4, #+-4 pixel shift max\n",
    "        height_shift_range=4,#+-4 pixel shift max\n",
    "        cval=0, #zero padding\n",
    "        fill_mode='constant' #zero padding\n",
    "        )\n",
    "\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "\n",
    "history=resnet50_cifar10.fit(train_generator,\n",
    "                   steps_per_epoch = step_size_train,\n",
    "                   epochs = epochs,\n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c80e85",
   "metadata": {},
   "source": [
    "# Adding SE layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14914249",
   "metadata": {},
   "source": [
    "### This is what we had before: normal resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.summary()\n",
    "import pydot\n",
    "keras.utils.plot_model(resnet50, to_file='resnet50.png',show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8588e0e1",
   "metadata": {},
   "source": [
    "### List of layers where SE is going to be added after the output\n",
    "\n",
    "(Check resnet50.png for more information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef8e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[l.name for l in resnet50.layers]\n",
    "list_se=[]\n",
    "for i,name in enumerate(l):\n",
    "    if(i+1<len(l) and 'add' in l[i+1]):\n",
    "        print(name)\n",
    "        list_se.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Not used #######\n",
    "#custom SE Layer (not working)\n",
    "from tensorflow.python.keras.layers import GlobalAveragePooling2D\n",
    "class SE_layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio=16,initializer=\"he_normal\", **kwargs):\n",
    "        super(SE_layer, self).__init__(**kwargs)\n",
    "        self.initializer = keras.initializers.get(initializer)\n",
    "        self.ratio=ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        out_dim = input_shape[-1]\n",
    "    def call(self, inputs): \n",
    "        print(inputs.shape[-1])\n",
    "        out_dim=inputs.shape[-1]\n",
    "        F_sq = GlobalAveragePooling2D()(inputs) #squeeze\n",
    "        F_ex = Dense(out_dim / self.ratio,activation='relu')(F_sq)\n",
    "        F_ex = Dense(out_dim,activation='sigmoid')(F_ex)\n",
    "        F_ex = tf.reshape(F_ex, [-1,1,1,out_dim])\n",
    "        F_scale = inputs * F_ex\n",
    "        return F_scale\n",
    "\n",
    "    def get_config(self):\n",
    "        # Implement get_config to enable serialization.\n",
    "        base_config = super(SE_layer, self).get_config()\n",
    "        config = {\"initializer\": keras.initializers.serialize(self.initializer)}\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58068e4e",
   "metadata": {},
   "source": [
    "### Adding SE layers before 'add' layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078901e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### add SE layers to model ##########\n",
    "# input: model\n",
    "#        l: list l of layer names where SE layers are going to go after\n",
    "#        ratio : SE ratio\n",
    "#        modelname: name of new model\n",
    "#\n",
    "# Output: modified model with SE layers at specified locations\n",
    "# See https://stackoverflow.com/questions/49492255/how-to-replace-or-insert-intermediate-layer-in-keras-model to understand the function\n",
    "##########################################\n",
    "\n",
    "def add_SE(model, l,ratio,modelname=None):\n",
    "    se_num =1\n",
    "    # Auxiliary dictionary to describe the network graph\n",
    "    network_dict = {'input_layers_of': {}, 'new_output_tensor_of': {}}\n",
    "\n",
    "    # Set the input layers of each layer\n",
    "    for layer in model.layers:\n",
    "        for node in layer._outbound_nodes:\n",
    "            layer_name = node.outbound_layer.name\n",
    "            if layer_name not in network_dict['input_layers_of']:\n",
    "                network_dict['input_layers_of'].update(\n",
    "                        {layer_name: [layer.name]})\n",
    "            else:\n",
    "                network_dict['input_layers_of'][layer_name].append(layer.name)\n",
    "\n",
    "    # Set the output tensor of the input layer\n",
    "    network_dict['new_output_tensor_of'].update(\n",
    "            {model.layers[0].name: model.input})\n",
    "\n",
    "    # Iterate over all layers after the input\n",
    "    model_outputs = []\n",
    "    for layer in model.layers[1:]:\n",
    "\n",
    "        # Determine input tensors\n",
    "        layer_input = [network_dict['new_output_tensor_of'][layer_aux] \n",
    "                for layer_aux in network_dict['input_layers_of'][layer.name]]\n",
    "        if len(layer_input) == 1:\n",
    "            layer_input = layer_input[0]\n",
    "\n",
    "        # Insert SE layers if name matches the argument list\n",
    "        if layer.name in l:\n",
    "            #input of SE\n",
    "            x = layer(layer_input)\n",
    "            \n",
    "            ### adding SE layers\n",
    "            out_dim=layer.output_shape[-1]\n",
    "            #squeeze layer\n",
    "            F_sq = GlobalAveragePooling2D(name='SE'+str(se_num)+'_global_avg')(x) #squeeze\n",
    "            #Excitation with 2 fully connected layers\n",
    "            F_ex = Dense(out_dim / ratio,activation='relu', name='SE'+str(se_num)+'_dense_relu')(F_sq)\n",
    "            F_ex = Dense(out_dim,activation='sigmoid', name='SE'+str(se_num)+'_dense_sig')(F_ex)\n",
    "            #Output : rescaling\n",
    "            F_ex = tf.reshape(F_ex, [-1,1,1,out_dim])\n",
    "            x=keras.layers.multiply([x,F_ex], name='SE'+str(se_num)+'_scaling')\n",
    "            \n",
    "            se_num+=1 # for naming\n",
    "            print('added SE after ',layer.name)\n",
    "        else:\n",
    "            x = layer(layer_input)\n",
    "\n",
    "        # Set new output tensor (the original one, or the one of the inserted\n",
    "        # layer)\n",
    "        network_dict['new_output_tensor_of'].update({layer.name: x})\n",
    "\n",
    "        # Renaming model\n",
    "        if layer.name in model.output_names:\n",
    "            model_outputs.append(x)\n",
    "        my_final_model= Model(inputs=model.inputs, outputs=model_outputs)\n",
    "        if (modelname!=None):\n",
    "            my_final_model._name = modelname\n",
    "        else:\n",
    "            my_final_model._name='SE_'+model._name\n",
    "    return my_final_model\n",
    "\n",
    "SE_ResNet50 = ResNet50(include_top=False, weights=None)\n",
    "def SE_factory(ratio):\n",
    "    return SE_layer(ratio=ratio)\n",
    "\n",
    "SE_ResNet50 = add_SE(SE_ResNet50, list_se,ratio=16)\n",
    "#SE_ResNet50.save('temp.h5')\n",
    "#SE_ResNet50 = keras.models.load_model('temp.h5',custom_objects={'SE_layer': SE_layer})\n",
    "SE_ResNet50.summary()\n",
    "keras.utils.plot_model(SE_ResNet50, to_file='test.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440adeba",
   "metadata": {},
   "source": [
    "### Adding topo layer, and input preprocessing (different resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "# Preprocess for ResNet50 input size\n",
    "x = preprocess_input(inputs)\n",
    "# ResNet50\n",
    "x = SE_ResNet50(x)\n",
    "# Add top layer again\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "#10 classes for cifar 10\n",
    "preds=Dense(10,activation='softmax')(x)\n",
    "SE_resnet50_cifar10=Model(inputs=inputs,outputs=preds)\n",
    "SE_resnet50_cifar10.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4d7ee",
   "metadata": {},
   "source": [
    "# Todo : train model with custom loop, adaptive learning rate, saving model every k epochs etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d76e43",
   "metadata": {},
   "source": [
    "# Top n accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_acc(pred, targets,n=1):\n",
    "    acc=np.mean(tf.keras.metrics.top_k_categorical_accuracy(targets, pred, k=n).numpy())\n",
    "    print(\"top\",n,'accuracy:',acc,sep=' ')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e00f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=resnet50_cifar10.predict(x_test)\n",
    "top_n_acc(preds,y_test,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
